{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Assignment-1: Linear Regression Model for Employee Attrition Prediction (From Scratch)\n",
                "\n",
                "**Dataset:** HR_Employee.csv  \n",
                "**Target Variable:** Attrition  \n",
                "**Input Variables (8):** Age, MonthlyIncome, TotalWorkingYears, YearsAtCompany, DistanceFromHome, JobSatisfaction, EnvironmentSatisfaction, YearsWithCurrManager  \n",
                "**Note:** Linear Regression is implemented from scratch using NumPy (Normal Equation), without using scikit-learn."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "print(\"Libraries imported successfully! (No scikit-learn used)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load the Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv('HR_Employee.csv')\n",
                "print(f\"Dataset Shape: {df.shape}\")\n",
                "print(f\"Number of Rows: {df.shape[0]}\")\n",
                "print(f\"Number of Columns: {df.shape[1]}\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Dataset Overview"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 60)\n",
                "print(\"DATASET INFO\")\n",
                "print(\"=\" * 60)\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 60)\n",
                "print(\"STATISTICAL SUMMARY\")\n",
                "print(\"=\" * 60)\n",
                "df.describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 60)\n",
                "print(\"MISSING VALUES\")\n",
                "print(\"=\" * 60)\n",
                "print(df.isnull().sum())\n",
                "print(f\"\\nTotal Missing Values: {df.isnull().sum().sum()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 60)\n",
                "print(\"TARGET VARIABLE DISTRIBUTION\")\n",
                "print(\"=\" * 60)\n",
                "print(df['Attrition'].value_counts())\n",
                "print(f\"\\nAttrition Rate: {df['Attrition'].value_counts(normalize=True)['Yes']*100:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Exploratory Data Analysis (EDA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Target variable distribution\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
                "\n",
                "colors = ['#2ecc71', '#e74c3c']\n",
                "df['Attrition'].value_counts().plot(kind='bar', ax=axes[0], color=colors, edgecolor='black')\n",
                "axes[0].set_title('Attrition Count', fontsize=14, fontweight='bold')\n",
                "axes[0].set_xlabel('Attrition')\n",
                "axes[0].set_ylabel('Count')\n",
                "axes[0].tick_params(axis='x', rotation=0)\n",
                "\n",
                "df['Attrition'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%', colors=colors, startangle=90)\n",
                "axes[1].set_title('Attrition Distribution', fontsize=14, fontweight='bold')\n",
                "axes[1].set_ylabel('')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Distribution of selected input features\n",
                "input_features = ['Age', 'MonthlyIncome', 'TotalWorkingYears', 'YearsAtCompany',\n",
                "                   'DistanceFromHome', 'JobSatisfaction', 'EnvironmentSatisfaction', 'YearsWithCurrManager']\n",
                "\n",
                "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
                "axes = axes.flatten()\n",
                "\n",
                "for i, col in enumerate(input_features):\n",
                "    axes[i].hist(df[col], bins=20, color='#3498db', edgecolor='black', alpha=0.7)\n",
                "    axes[i].set_title(f'Distribution of {col}', fontsize=11, fontweight='bold')\n",
                "    axes[i].set_xlabel(col)\n",
                "    axes[i].set_ylabel('Frequency')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Box plots - Features vs Attrition\n",
                "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
                "axes = axes.flatten()\n",
                "\n",
                "for i, col in enumerate(input_features):\n",
                "    sns.boxplot(x='Attrition', y=col, data=df, ax=axes[i], palette=colors)\n",
                "    axes[i].set_title(f'{col} vs Attrition', fontsize=11, fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Encode Attrition: Yes = 1, No = 0\n",
                "df['Attrition_Encoded'] = df['Attrition'].map({'Yes': 1, 'No': 0})\n",
                "\n",
                "# Correlation heatmap for selected features\n",
                "selected_cols = input_features + ['Attrition_Encoded']\n",
                "corr_matrix = df[selected_cols].corr()\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.heatmap(corr_matrix, annot=True, cmap='RdYlBu_r', center=0, fmt='.2f',\n",
                "            linewidths=0.5, square=True)\n",
                "plt.title('Correlation Heatmap - Selected Features', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Data Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define input (X) and output (y)\n",
                "X = df[input_features].values\n",
                "y = df['Attrition_Encoded'].values\n",
                "\n",
                "print(\"Input Features (X):\")\n",
                "print(input_features)\n",
                "print(f\"\\nShape of X: {X.shape}\")\n",
                "print(f\"Shape of y: {y.shape}\")\n",
                "print(f\"\\nTarget Encoding: No -> 0, Yes -> 1\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train-Test Split from scratch (80-20 split)\n",
                "np.random.seed(42)\n",
                "indices = np.random.permutation(len(X))\n",
                "split_point = int(0.8 * len(X))\n",
                "\n",
                "train_idx = indices[:split_point]\n",
                "test_idx = indices[split_point:]\n",
                "\n",
                "X_train, X_test = X[train_idx], X[test_idx]\n",
                "y_train, y_test = y[train_idx], y[test_idx]\n",
                "\n",
                "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
                "print(f\"Testing set size:  {X_test.shape[0]} samples\")\n",
                "print(f\"\\nTraining set shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
                "print(f\"Testing set shape:  X_test={X_test.shape}, y_test={y_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Linear Regression from Scratch\n",
                "\n",
                "Using the **Normal Equation**:  \n",
                "$$\\theta = (X^T X)^{-1} X^T y$$\n",
                "\n",
                "Where:\n",
                "- $X$ = input feature matrix (with bias column of 1s)\n",
                "- $y$ = target vector\n",
                "- $\\theta$ = model parameters (weights + bias)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class LinearRegressionScratch:\n",
                "    \"\"\"\n",
                "    Linear Regression implemented from scratch using the Normal Equation.\n",
                "    No scikit-learn dependency.\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self):\n",
                "        self.weights = None   # model weights (coefficients)\n",
                "        self.bias = None      # intercept\n",
                "    \n",
                "    def fit(self, X, y):\n",
                "        \"\"\"Train the model using the Normal Equation: theta = (X^T X)^(-1) X^T y\"\"\"\n",
                "        n_samples = X.shape[0]\n",
                "        \n",
                "        # Add bias column (column of 1s) to X\n",
                "        X_bias = np.c_[np.ones(n_samples), X]\n",
                "        \n",
                "        # Normal Equation: theta = (X^T X)^(-1) X^T y\n",
                "        XtX = X_bias.T.dot(X_bias)\n",
                "        Xty = X_bias.T.dot(y)\n",
                "        theta = np.linalg.inv(XtX).dot(Xty)\n",
                "        \n",
                "        # Extract bias and weights\n",
                "        self.bias = theta[0]\n",
                "        self.weights = theta[1:]\n",
                "        \n",
                "        return self\n",
                "    \n",
                "    def predict(self, X):\n",
                "        \"\"\"Make predictions: y_pred = X * weights + bias\"\"\"\n",
                "        return X.dot(self.weights) + self.bias\n",
                "\n",
                "print(\"Linear Regression class defined from scratch (Normal Equation).\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train the model\n",
                "model = LinearRegressionScratch()\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "print(\"Model trained successfully!\")\n",
                "print(f\"\\nIntercept (bias): {model.bias:.4f}\")\n",
                "print(f\"\\nCoefficients (weights):\")\n",
                "for feature, coef in zip(input_features, model.weights):\n",
                "    print(f\"  {feature:30s}: {coef:.6f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Make Predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predict on test set\n",
                "y_pred = model.predict(X_test)\n",
                "\n",
                "# Display first 10 predictions\n",
                "results_df = pd.DataFrame({\n",
                "    'Actual': y_test[:10],\n",
                "    'Predicted (Raw)': np.round(y_pred[:10], 4),\n",
                "    'Predicted (Rounded)': (y_pred[:10] >= 0.5).astype(int)\n",
                "})\n",
                "print(\"First 10 Predictions:\")\n",
                "print(results_df.to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Evaluation Metrics (From Scratch)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ---- Regression Metrics (From Scratch) ----\n",
                "\n",
                "def mean_squared_error(y_true, y_pred):\n",
                "    return np.mean((y_true - y_pred) ** 2)\n",
                "\n",
                "def root_mean_squared_error(y_true, y_pred):\n",
                "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
                "\n",
                "def mean_absolute_error(y_true, y_pred):\n",
                "    return np.mean(np.abs(y_true - y_pred))\n",
                "\n",
                "def r2_score(y_true, y_pred):\n",
                "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
                "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
                "    return 1 - (ss_res / ss_tot)\n",
                "\n",
                "mse = mean_squared_error(y_test, y_pred)\n",
                "rmse = root_mean_squared_error(y_test, y_pred)\n",
                "mae = mean_absolute_error(y_test, y_pred)\n",
                "r2 = r2_score(y_test, y_pred)\n",
                "\n",
                "print(\"=\" * 50)\n",
                "print(\"REGRESSION EVALUATION METRICS\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"Mean Squared Error (MSE):       {mse:.4f}\")\n",
                "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
                "print(f\"Mean Absolute Error (MAE):      {mae:.4f}\")\n",
                "print(f\"R-squared (R²) Score:           {r2:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Classification Analysis (Threshold = 0.5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ---- Classification Metrics (From Scratch) ----\n",
                "\n",
                "# Convert predictions to binary\n",
                "y_pred_class = (y_pred >= 0.5).astype(int)\n",
                "\n",
                "# Accuracy\n",
                "def accuracy_score(y_true, y_pred):\n",
                "    return np.sum(y_true == y_pred) / len(y_true)\n",
                "\n",
                "# Confusion Matrix\n",
                "def confusion_matrix(y_true, y_pred):\n",
                "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
                "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
                "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
                "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
                "    return np.array([[tn, fp], [fn, tp]])\n",
                "\n",
                "# Precision, Recall, F1-Score\n",
                "def precision_score(y_true, y_pred):\n",
                "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
                "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
                "    return tp / (tp + fp) if (tp + fp) > 0 else 0\n",
                "\n",
                "def recall_score(y_true, y_pred):\n",
                "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
                "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
                "    return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
                "\n",
                "def f1_score(y_true, y_pred):\n",
                "    p = precision_score(y_true, y_pred)\n",
                "    r = recall_score(y_true, y_pred)\n",
                "    return 2 * (p * r) / (p + r) if (p + r) > 0 else 0\n",
                "\n",
                "acc = accuracy_score(y_test, y_pred_class)\n",
                "prec = precision_score(y_test, y_pred_class)\n",
                "rec = recall_score(y_test, y_pred_class)\n",
                "f1 = f1_score(y_test, y_pred_class)\n",
                "cm = confusion_matrix(y_test, y_pred_class)\n",
                "\n",
                "print(\"=\" * 50)\n",
                "print(\"CLASSIFICATION METRICS (Threshold = 0.5)\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"Accuracy:  {acc:.4f} ({acc*100:.2f}%)\")\n",
                "print(f\"Precision: {prec:.4f}\")\n",
                "print(f\"Recall:    {rec:.4f}\")\n",
                "print(f\"F1-Score:  {f1:.4f}\")\n",
                "print(f\"\\nConfusion Matrix:\")\n",
                "print(f\"  TN={cm[0][0]}  FP={cm[0][1]}\")\n",
                "print(f\"  FN={cm[1][0]}  TP={cm[1][1]}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion Matrix Heatmap\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
                "            xticklabels=['No Attrition', 'Attrition'],\n",
                "            yticklabels=['No Attrition', 'Attrition'])\n",
                "plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
                "plt.xlabel('Predicted', fontsize=12)\n",
                "plt.ylabel('Actual', fontsize=12)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Visualizations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Actual vs Predicted\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.scatter(y_test, y_pred, alpha=0.5, color='#3498db', edgecolors='black', linewidth=0.5)\n",
                "plt.plot([0, 1], [0, 1], 'r--', linewidth=2, label='Ideal Prediction Line')\n",
                "plt.xlabel('Actual Values', fontsize=12)\n",
                "plt.ylabel('Predicted Values', fontsize=12)\n",
                "plt.title('Actual vs Predicted Values', fontsize=14, fontweight='bold')\n",
                "plt.legend(fontsize=11)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Residual Plot\n",
                "residuals = y_test - y_pred\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.scatter(y_pred, residuals, alpha=0.5, color='#e74c3c', edgecolors='black', linewidth=0.5)\n",
                "plt.axhline(y=0, color='black', linestyle='--', linewidth=1.5)\n",
                "plt.xlabel('Predicted Values', fontsize=12)\n",
                "plt.ylabel('Residuals', fontsize=12)\n",
                "plt.title('Residual Plot', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Distribution of Residuals\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.hist(residuals, bins=30, color='#9b59b6', edgecolor='black', alpha=0.7)\n",
                "plt.axvline(x=0, color='red', linestyle='--', linewidth=1.5)\n",
                "plt.xlabel('Residuals', fontsize=12)\n",
                "plt.ylabel('Frequency', fontsize=12)\n",
                "plt.title('Distribution of Residuals', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature Importance (Coefficients)\n",
                "coef_df = pd.DataFrame({\n",
                "    'Feature': input_features,\n",
                "    'Coefficient': model.weights\n",
                "}).sort_values(by='Coefficient', key=abs, ascending=True)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "colors_bar = ['#e74c3c' if c < 0 else '#2ecc71' for c in coef_df['Coefficient']]\n",
                "plt.barh(coef_df['Feature'], coef_df['Coefficient'], color=colors_bar, edgecolor='black')\n",
                "plt.xlabel('Coefficient Value', fontsize=12)\n",
                "plt.ylabel('Feature', fontsize=12)\n",
                "plt.title('Feature Importance (Linear Regression Coefficients)', fontsize=14, fontweight='bold')\n",
                "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Summary\n",
                "\n",
                "### Model Details:\n",
                "- **Algorithm:** Linear Regression (implemented from scratch using Normal Equation)\n",
                "- **No scikit-learn used** — all computations done with NumPy\n",
                "- **Target Variable:** Attrition (encoded as 0 = No, 1 = Yes)\n",
                "- **Input Features (8):** Age, MonthlyIncome, TotalWorkingYears, YearsAtCompany, DistanceFromHome, JobSatisfaction, EnvironmentSatisfaction, YearsWithCurrManager\n",
                "- **Train-Test Split:** 80% Training, 20% Testing (manual random split)\n",
                "\n",
                "### What was implemented from scratch:\n",
                "1. **Linear Regression Model** — using the Normal Equation: θ = (XᵀX)⁻¹Xᵀy\n",
                "2. **Train-Test Split** — using numpy random permutation\n",
                "3. **Regression Metrics** — MSE, RMSE, MAE, R² Score\n",
                "4. **Classification Metrics** — Accuracy, Precision, Recall, F1-Score, Confusion Matrix\n",
                "\n",
                "### Key Observations:\n",
                "- Linear Regression provides continuous predictions between 0 and 1 for this binary classification task.\n",
                "- The model coefficients indicate the relative importance and direction of influence of each feature on attrition.\n",
                "- Features with negative coefficients are associated with lower attrition, while positive coefficients indicate higher attrition risk."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}